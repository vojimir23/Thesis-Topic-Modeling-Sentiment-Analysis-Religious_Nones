{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bd860a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T00:44:17.544978Z",
     "start_time": "2023-05-27T00:44:06.639855Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vojimir Ranitovic\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.1.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "from pprint import pprint\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import contractions\n",
    "import string\n",
    "import openpyxl\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models.phrases import Phrases, Phraser, ENGLISH_CONNECTOR_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50f545dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T13:34:04.433792Z",
     "start_time": "2023-05-21T13:33:58.836738Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>followers</th>\n",
       "      <th>tweet_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAAPORG</td>\n",
       "      <td>b'This Pakistani lecturer has spent six years ...</td>\n",
       "      <td>2019-12-06 10:29:17+00:00</td>\n",
       "      <td>Islamabad, Pakistan</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>241</td>\n",
       "      <td>https://twitter.com/AAAPORG/status/12028977947...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAAPORG</td>\n",
       "      <td>b'We stands with the students marching for the...</td>\n",
       "      <td>2019-11-29 07:06:57+00:00</td>\n",
       "      <td>Islamabad, Pakistan</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>241</td>\n",
       "      <td>https://twitter.com/AAAPORG/status/12003101619...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  username                                              tweet  \\\n",
       "0  AAAPORG  b'This Pakistani lecturer has spent six years ...   \n",
       "1  AAAPORG  b'We stands with the students marching for the...   \n",
       "\n",
       "                        date             location  likes  retweets  followers  \\\n",
       "0  2019-12-06 10:29:17+00:00  Islamabad, Pakistan     10         4        241   \n",
       "1  2019-11-29 07:06:57+00:00  Islamabad, Pakistan      6         0        241   \n",
       "\n",
       "                                           tweet_url  \n",
       "0  https://twitter.com/AAAPORG/status/12028977947...  \n",
       "1  https://twitter.com/AAAPORG/status/12003101619...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r\"C:\\Users\\Vojimir Ranitovic\\Desktop\\NON RELIGIOUS FINAL\\all_tweets.csv\"\n",
    "df = pd.read_csv(path, header=None,encoding='utf-8',low_memory=False)\n",
    "df.columns =['username', 'tweet', 'date', 'location',\"likes\",\"retweets\",\"followers\",\"tweet_url\"]\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b440fbcc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T13:34:06.677743Z",
     "start_time": "2023-05-21T13:34:05.882530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264\n",
      "username     1224446\n",
      "tweet        1224446\n",
      "date         1224446\n",
      "location      795230\n",
      "likes        1224446\n",
      "retweets     1224446\n",
      "followers    1224446\n",
      "tweet_url    1224446\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"username\"].nunique())\n",
    "print(df.count()) # There are this many tweets, but some of them are duplicates-retweets.etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "468f0905",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T13:34:11.632643Z",
     "start_time": "2023-05-21T13:34:09.234505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "username         264\n",
      "tweet        1183431\n",
      "date         1145913\n",
      "location         183\n",
      "likes           1686\n",
      "retweets         626\n",
      "followers        268\n",
      "tweet_url    1183431\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df=df.drop_duplicates(subset='tweet', keep='first')\n",
    "print(df.nunique()) #delete duplicate tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "454ac1ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T13:34:15.148941Z",
     "start_time": "2023-05-21T13:34:15.122993Z"
    }
   },
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend([\"amp\",\"u\",\"tweet\",\"retweet\",\"twitter\",\"many\",\"today\",\"time\",\"thing\",\"good\",\"humanists\",\"amp\",\"retweets\",\"tweets\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1ef3f0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T13:34:16.631466Z",
     "start_time": "2023-05-21T13:34:16.616509Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    punctuation = string.punctuation + 'â€'\n",
    "    tweet = tweet.lower()\n",
    "    tweet = contractions.fix(tweet)\n",
    "    tweet = re.sub(r'^b(?:\"|\\')?(.*)$', r'\\1', tweet)\n",
    "    tweet = re.sub(r\"\\\\n\", ' ', tweet)\n",
    "    tweet = re.sub(r'http\\S+', '', tweet)\n",
    "    tweet = re.sub(r'#\\s*\\w+', '', tweet)\n",
    "    tweet = re.sub(r'@\\s*\\w+', '', tweet)\n",
    "    tweet = re.sub(r'\\\\[a-z0-9]{3}', '', tweet)\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet)\n",
    "    tweet = re.sub(r'[^\\x00-\\x7F]+', ' ', tweet)  # Remove non-ASCII characters\n",
    "    tweet = tweet.encode('ascii', 'ignore').decode('utf-8')  # Remove non-ASCII characters\n",
    "    tweet = re.sub(r'\\b\\d+\\b', '', tweet)  # Remove all numbers\n",
    "    tweet = tweet.translate(tweet.maketrans('', '', punctuation))\n",
    "    tweet = ' '.join([word for word in tweet.split() if word not in stop_words])\n",
    "    tweet = ' '.join([word for word in tweet.split() if len(word) > 3 or word in [\"no\", \"not\", \"god\", \"end\", \"yes\"]])\n",
    "    return tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5eafa538",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T13:36:03.238528Z",
     "start_time": "2023-05-21T13:34:19.362512Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>followers</th>\n",
       "      <th>tweet_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAAPORG</td>\n",
       "      <td>b'This Pakistani lecturer has spent six years in prison and is facing the death sentence \\xe2\\x80\\x93 for allegedly insulting the Prophet Mohammed.\\n#freeJunaidHafeez'</td>\n",
       "      <td>pakistani lecturer spent years prison facing death sentence allegedly insulting prophet mohammed</td>\n",
       "      <td>2019-12-06 10:29:17+00:00</td>\n",
       "      <td>Islamabad, Pakistan</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>241</td>\n",
       "      <td>https://twitter.com/AAAPORG/status/1202897794702434304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAAPORG</td>\n",
       "      <td>b'We stands with the students marching for their rights across Pakistan. Peaceful protest is a human right. #StudentSolidarityMarch https://t.co/TlkBlhvRVr'</td>\n",
       "      <td>stands students marching rights across pakistan peaceful protest human right</td>\n",
       "      <td>2019-11-29 07:06:57+00:00</td>\n",
       "      <td>Islamabad, Pakistan</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>241</td>\n",
       "      <td>https://twitter.com/AAAPORG/status/1200310161904164864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  username  \\\n",
       "0  AAAPORG   \n",
       "1  AAAPORG   \n",
       "\n",
       "                                                                                                                                                                     tweet  \\\n",
       "0  b'This Pakistani lecturer has spent six years in prison and is facing the death sentence \\xe2\\x80\\x93 for allegedly insulting the Prophet Mohammed.\\n#freeJunaidHafeez'   \n",
       "1             b'We stands with the students marching for their rights across Pakistan. Peaceful protest is a human right. #StudentSolidarityMarch https://t.co/TlkBlhvRVr'   \n",
       "\n",
       "                                                                                        clean_tweet  \\\n",
       "0  pakistani lecturer spent years prison facing death sentence allegedly insulting prophet mohammed   \n",
       "1                      stands students marching rights across pakistan peaceful protest human right   \n",
       "\n",
       "                        date             location  likes  retweets  followers  \\\n",
       "0  2019-12-06 10:29:17+00:00  Islamabad, Pakistan     10         4        241   \n",
       "1  2019-11-29 07:06:57+00:00  Islamabad, Pakistan      6         0        241   \n",
       "\n",
       "                                                tweet_url  \n",
       "0  https://twitter.com/AAAPORG/status/1202897794702434304  \n",
       "1  https://twitter.com/AAAPORG/status/1200310161904164864  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None) \n",
    "df.insert(df.columns.get_loc(\"tweet\")+1, \"clean_tweet\", df[\"tweet\"].map(lambda a:clean_tweet(a)))\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e1421eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T13:36:13.510697Z",
     "start_time": "2023-05-21T13:36:11.474654Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "username           264\n",
       "tweet          1183431\n",
       "clean_tweet    1001070\n",
       "date           1145913\n",
       "location           183\n",
       "likes             1686\n",
       "retweets           626\n",
       "followers          268\n",
       "tweet_url      1183431\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45feec37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T13:36:17.638522Z",
     "start_time": "2023-05-21T13:36:15.255649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "username           264\n",
      "tweet          1001070\n",
      "clean_tweet    1001070\n",
      "date            968296\n",
      "location           183\n",
      "likes             1621\n",
      "retweets           597\n",
      "followers          268\n",
      "tweet_url      1001070\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df=df.drop_duplicates(subset='clean_tweet', keep='first')\n",
    "print(df.nunique()) #delete duplicate tweets again because there were a lot of tweets that are the same (only url links were different)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e358d55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T14:24:58.223785Z",
     "start_time": "2023-05-21T13:37:55.406174Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load Spacy Lemmatizer\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "# Preprocessing\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())  # Tokenization\n",
    "    tokens = [token for token in tokens if token.isalpha()]  # Remove non-alphabetic tokens\n",
    "    tokens = [token for token in tokens if token not in stop_words]  # Remove stop words\n",
    "    lemmas = [token.lemma_ for token in nlp(\" \".join(tokens)) if token.pos_ in ['NOUN', 'ADJ']]  # Lemmatization with Spacy, allowed POS tags\n",
    "    return \" \".join(lemmas)\n",
    "\n",
    "df[\"preprocessed_tweet\"] = df[\"clean_tweet\"].apply(preprocess_text)\n",
    "\n",
    "# Remove duplicate rows based on \"preprocessed_tweet\" column\n",
    "df.drop_duplicates(subset=\"preprocessed_tweet\", inplace=True)\n",
    "\n",
    "# Create bigrams and trigrams\n",
    "corpus = df[\"preprocessed_tweet\"].apply(str.split)\n",
    "phrases = Phrases(corpus, min_count=100, threshold=150, connector_words=ENGLISH_CONNECTOR_WORDS)\n",
    "bigram = Phraser(phrases)\n",
    "corpus = corpus.apply(lambda x: bigram[x])\n",
    "trigram = Phrases(corpus, min_count=100, threshold=150, connector_words=ENGLISH_CONNECTOR_WORDS)\n",
    "trigram = Phraser(trigram)\n",
    "corpus = corpus.apply(lambda x: trigram[bigram[x]])\n",
    "\n",
    "# Convert corpus to a list of strings\n",
    "corpus = corpus.apply(lambda x: ' '.join(x)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3630e339",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T14:27:59.633182Z",
     "start_time": "2023-05-21T14:27:49.796213Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('all_dataset_lemmatized.csv', index=False)\n",
    "\n",
    "# Save the corpus to a text file\n",
    "with open('corpus.txt', 'w') as file:\n",
    "    file.write('\\n'.join(corpus))\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.545px",
    "left": "754.901px",
    "right": "20px",
    "top": "382.965px",
    "width": "349.982px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
